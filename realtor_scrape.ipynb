{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to install packages\n",
    "#conda install -c conda-forge selenium\n",
    "#!pip install fake_useragent\n",
    "#!pip install eventlet\n",
    "#!pip install python-settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time, os\n",
    "import re\n",
    "import random\n",
    "from random import randint\n",
    "import random\n",
    "from time import sleep\n",
    "\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper files\n",
    "import get_proxies as proxies\n",
    "import extractors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Mongo collection for urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client['philadelphia_home_prices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prices_messy', 'listing_urls', 'listing_data']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to delete the collection\n",
    "#db.drop_collection('listing_urls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prices_messy', 'listing_urls', 'listing_data']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "CollectionInvalid",
     "evalue": "collection listing_urls already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCollectionInvalid\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f89e26be8af4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'listing_urls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pymongo/database.py\u001b[0m in \u001b[0;36mcreate_collection\u001b[0;34m(self, name, codec_options, read_preference, write_concern, read_concern, session, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                     name in self.list_collection_names(\n\u001b[1;32m    413\u001b[0m                         filter={\"name\": name}, session=s)):\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mCollectionInvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"collection %s already exists\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m             return Collection(self, name, True, codec_options,\n",
      "\u001b[0;31mCollectionInvalid\u001b[0m: collection listing_urls already exists"
     ]
    }
   ],
   "source": [
    "col = db.create_collection('listing_urls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prices_messy', 'listing_urls', 'listing_data']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scrape pages for listing urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.realtor.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 44 listings per page. Choose start and stop page\n",
    "page_from = 26\n",
    "page_to = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = db.get_collection('listing_urls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrismalasics/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(page_from, page_to+1):\n",
    "    #print(i) #prints page that is open in case bot is detected\n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "    driver.get(url + 'soldhomeprices/Philadelphia_PA/pg-' + str(i))\n",
    "    \n",
    "    sleep(random.uniform(60,120))\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    page = str(soup.find_all('div', class_='photo-wrap'))\n",
    "    extensions = re.findall(r'[A-z]+-[A-z]+\\/[0-9-A-z]+[^\"]', page)\n",
    "    \n",
    "    if len(extensions) == 0:\n",
    "        print('bot is caught on page {}'.format(i))\n",
    "        break\n",
    "        \n",
    "    for i in extensions:\n",
    "        page_url = url + i\n",
    "        page = {'url': page_url}\n",
    "        col.insert_one(page)\n",
    "        \n",
    "    sleep(random.uniform(1,3))\n",
    "    \n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrismalasics/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull urls from mongoDB into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull urls from mongo db\n",
    "cursor = db.listing_urls.find({})\n",
    "listings = list(cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dictionary values to list\n",
    "listing_urls_list = []\n",
    "for i in listings:\n",
    "    url = i['url']\n",
    "    listing_urls_list.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.realtor.com/realestateandhomes-detail/1232-N-Mascher-St-Apt-A_Philadelphia_PA_19122_M49182-95881',\n",
       " 'https://www.realtor.com/realestateandhomes-detail/212-Carpenter-St-Rear-C_Philadelphia_PA_19147_M34206-29412',\n",
       " 'https://www.realtor.com/realestateandhomes-detail/1211-E-Cheltenham-Ave_Philadelphia_PA_19124_M33700-20336',\n",
       " 'https://www.realtor.com/realestateandhomes-detail/1002-Brandywine-St_Philadelphia_PA_19123_M39147-93479',\n",
       " 'https://www.realtor.com/realestateandhomes-detail/2607-N-31st-St_Philadelphia_PA_19132_M32883-74202']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see first 5 in list\n",
    "listing_urls_list[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data from urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### new collection for listing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment the code you need to use\n",
    "#db.create_collection('listing_data')\n",
    "col = db.get_collection('listing_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrismalasics/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: collection_names is deprecated. Use list_collection_names instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['prices_messy', 'listing_urls', 'listing_data']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to drop\n",
    "#db.drop_collection('listing_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrismalasics/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: collection_names is deprecated. Use list_collection_names instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['prices_messy', 'listing_urls', 'listing_data']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rotate proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-03 15:23:49,574 root   DEBUG    === Initialized Proxy Parsers ===\n",
      "2020-11-03 15:23:49,575 root   DEBUG    \t FreeProxy parser of 'http://free-proxy-list.net' with required bandwidth: '150' KBs\n",
      "2020-11-03 15:23:49,575 root   DEBUG    \t PremProxy parser of 'https://premproxy.com/list/' with required bandwidth: '150' KBs\n",
      "2020-11-03 15:23:49,576 root   DEBUG    =================================\n",
      "2020-11-03 15:23:50,048 root   DEBUG    Added 300 proxies from FreeProxy\n",
      "2020-11-03 15:23:50,621 http_request_randomizer.requests.parsers.PremProxyParser DEBUG    Pages: {'', '06.htm', '03.htm', '08.htm', '05.htm', '10.htm', '04.htm', '09.htm', '07.htm', '02.htm'}\n",
      "2020-11-03 15:23:51,202 http_request_randomizer.requests.parsers.js.UnPacker INFO     JS UnPacker init path: https://premproxy.com/js/394a0.js\n",
      "2020-11-03 15:23:51,787 http_request_randomizer.requests.parsers.js.UnPacker DEBUG    portmap: {'re356': '8080', 'r1000': '32108', 'ra8f9': '51671', 'rdf03': '8087', 're2a2': '8000', 'r7241': '999', 'r9ec3': '54697', 'rb7eb': '8081', 'r1623': '3000', 'r6391': '34244', 'r7632': '53597', 'r0403': '80', 'r18c6': '52355', 'rc0bd': '37699', 're1d6': '83', 'r0d5f': '61967', 'ra379': '40137', 'r80b8': '32231', 'r13d7': '3128', 'r9477': '60020', 'rcda9': '57797', 'r4ad7': '8181', 'r069c': '53281', 'r2dc3': '808', 'r8082': '32378', 'ra462': '43388', 'ra2da': '65205', 'rc2fa': '55443', 'rc01e': '45521', 'r9088': '59557', 'rb67d': '32721', 're9b3': '40348', 'r97c7': '39150', 'rab08': '59880', 'r559d': '50846', 'r8f17': '3070', 'rdeb0': '37399', 'r8bd6': '46752', 'r646d': '34403', 'rbaab': '59144', 'r67b2': '59190', 'r0b16': '34273', 'rc1cd': '55472', 'rec8e': '43749', 'r7c13': '50991', 'r2083': '44612', 'r8540': '38525', 'rde53': '3838', 'rc621': '49929', 'rf224': '35942', 'r1132': '8118', 'ra3f7': '8028', 'r95eb': '53410', 'r36d8': '31870', 'ra2cf': '51489', 'r3cbc': '61279', 'r7d9c': '21213', 'r70c0': '41701', 'r9092': '9991', 'rd052': '8382', 'r8d57': '8193', 'r8634': '40014', 'r8131': '48434', 'r0808': '82', 'raf01': '81', 'rca5a': '84', 'rcc94': '45548', 'rd513': '54100', 'rcb8d': '58137', 'r5350': '9090', 'r5c9d': '34082', 'r0bb4': '5836', 'r7816': '41258', 'rbc98': '60088', 'rb499': '6000', 'r68b3': '58332', 'r9ab4': '45944', 'r5687': '32052', 'r911f': '58792', 'rfed5': '8197', 'rd99a': '8380', 'r8693': '53758', 'r62be': '51172', 'r9d3e': '30716', 'r98a3': '1234', 'rdee1': '8888', 'r1bd5': '33486', 'rca47': '1973', 'r6672': '9999', 'rbb13': '60792', 'r84ad': '8090', 'r5416': '47385', 'r71b8': '30677', 'r5f92': '48458', 'rc9a2': '48515', 'rce7b': '31398', 'reea1': '45282', 'raec7': '54018', 'rf96c': '42928', 'r77f8': '38057', 'r3d55': '54375', 'rfea2': '32392', 'rb0e4': '52271', 'r3078': '41043', 'r2cc4': '43631', 'r81de': '9001', 'ra11e': '56506', 'r461f': '23500', 'r6825': '61426', 'r3f20': '39272', 'rf494': '2107', 'rdadd': '7777', 'r50ac': '46340', 'r126d': '47548', 'r4ea4': '34808', 'r534c': '48970', 'r0c72': '38865', 'r8f5c': '45730', 'r091d': '3129', 'r818b': '44021', 'rdbcc': '41731', 'r761b': '50330', 'r135a': '47437', 'rdaa0': '53171', 'r2a32': '58928', 'r8a98': '37979', 'r7065': '36739', 'r05c9': '38510', 'r901d': '35953', 'rbe33': '41026', 'ra8f1': '39721', 'rd0ac': '45088', 'r5261': '56975', 'r1802': '56667', 'r3ddc': '33831', 'r26e0': '52184', 'r6cee': '55693', 'rcbeb': '58198', 'r5540': '43097', 're7e3': '44199', 'rf89f': '34638', 're3c4': '33855', 'rbebe': '59064', 'r9349': '42850', 'r3d0c': '8282', 'rb137': '38416', 'r1544': '54675', 're08c': '47504'}\n",
      "2020-11-03 15:23:57,640 root   DEBUG    Added 492 proxies from PremProxy\n",
      "2020-11-03 15:23:57,641 root   DEBUG    Total proxies = 1584\n",
      "2020-11-03 15:23:57,643 root   DEBUG    Filtered proxies = 1584\n"
     ]
    }
   ],
   "source": [
    "#get list of proxies from free-proxy.net\n",
    "proxies_address = proxies.proxy_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_from = 12\n",
    "listing_to = len(listing_urls_list)\n",
    "count = 0\n",
    "good_proxies = []\n",
    "bad_proxies = []\n",
    "bad_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import concurrent.futures\n",
    "from datetime import datetime\n",
    "import eventlet\n",
    "import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = eventlet.GreenPool(settings.max_threads)\n",
    "pile = eventlet.GreenPile(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_THREADS = 30\n",
    "\n",
    "for i in range(listing_from, listing_to+1): \n",
    "    print(i, listing_urls_list[i])\n",
    "\n",
    "    try:\n",
    "        PROXY = proxies[count].get_address()\n",
    "        webdriver.DesiredCapabilities.CHROME['proxy']={\n",
    "                                                        \"httpProxy\":PROXY,\n",
    "                                                       \"ftpProxy\":PROXY,\n",
    "                                                       \"sslProxy\":PROXY,\n",
    "                                                       \"proxyType\":\"MANUAL\",\n",
    "                                                        }\n",
    "        driver = webdriver.Chrome(chromedriver)\n",
    "        driver.get(listing_urls_list[i])\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        listing_data = get_data(soup)\n",
    "        good_proxies.append(proxy)\n",
    "\n",
    "    except:\n",
    "        bad_proxies.append(proxy)\n",
    "        count += 1\n",
    "        driver.close()\n",
    "        \n",
    "    driver.close()\n",
    "    \n",
    "    #insert listing data into mongo database\n",
    "    col.insert_one(listing_data)\n",
    "    print(listing_data)\n",
    "    count += 1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = min(MAX_THREADS, len(story_urls))\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=threads) as executor:\n",
    "    executor.map(download_url, story_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 https://www.realtor.com/realestateandhomes-detail/731-Thomas-Rd_Philadelphia_PA_19118_M35952-99959\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'proxy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-685ff7c191b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mPROXY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_address\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPROXY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'proxies' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-685ff7c191b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mtested_proxies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mbad_proxies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'proxy' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(listing_from, listing_to+1): \n",
    "    print(i, listing_urls_list[i])\n",
    "    check = False\n",
    "    state = False\n",
    "    while state==False:\n",
    "        try:\n",
    "            PROXY = proxies[count].get_address()\n",
    "            print(PROXY)\n",
    "            webdriver.DesiredCapabilities.CHROME['proxy']={\n",
    "                                                            \"httpProxy\":PROXY,\n",
    "                                                           \"ftpProxy\":PROXY,\n",
    "                                                           \"sslProxy\":PROXY,\n",
    "                                                           \"proxyType\":\"MANUAL\",\n",
    "                                                            }\n",
    "            driver = webdriver.Chrome(chromedriver)\n",
    "            driver.get(listing_urls_list[i])\n",
    "\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            listing_data = get_data(soup)\n",
    "            \n",
    "            try:\n",
    "                check = (soup.find('span', itemprop=\"streetAddress\")).text\n",
    "            except:\n",
    "                bad_url.append(listing_urls_list[i])\n",
    "                break\n",
    "      \n",
    "                \n",
    "            state = True\n",
    "            tested_proxies.append(proxy)\n",
    "        except:\n",
    "            bad_proxies.append(proxy)\n",
    "            count += 1\n",
    "            driver.close()\n",
    "        \n",
    "    driver.close()\n",
    "    \n",
    "    #insert listing data into mongo database\n",
    "    col.insert_one(listing_data)\n",
    "    print(listing_data)\n",
    "    count += 1\n",
    "    print(count)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    #if i//5 == 0:\n",
    "    #    sleep(random.uniform(60,120))\n",
    "        \n",
    "    ####     \n",
    "    #session=requests.Session()\n",
    "    #session.headers = user_agent#{'User-Agent': ua.random} #'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}\n",
    "    #print(user_agent)\n",
    "    ##base_url='https://www.realtor.com'\n",
    "    ##re_list=[]\n",
    "    ##realtor_default_count=44\n",
    "    ##page_counter=1\n",
    "    ##search_url=''.join([base_url, '/realestateandhomes-search/Sacramento_CA'])\n",
    "    #page=session.get(listing_urls_list[i])\n",
    "    #c=page.content\n",
    "    #soup=BeautifulSoup(c,\"html.parser\")\n",
    "    ####\n",
    "    \n",
    "    #options = Options()\n",
    "    #ua = UserAgent()\n",
    "    #userAgent = ua.random\n",
    "    #print(userAgent)\n",
    "    #options.add_argument(f'user-agent={userAgent}')\n",
    "    #driver = webdriver.Chrome(chrome_options=options, executable_path=chromedriver)\n",
    "    #driver.get(listing_urls_list[i])\n",
    "    \n",
    "    #sleep(random.uniform(120,180)) #pause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = {'hi':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello['hi'] == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(listing_from, listing_to+1): \n",
    "    \n",
    "    print(i, listing_urls_list[i])\n",
    "    \n",
    "    #ua = UserAgent()\n",
    "    #user_agent = {'User-agent': ua.random}\n",
    "    #print(user_agent)\n",
    "\n",
    "    #response  = requests.get(listing_urls_list[i], headers = user_agent)\n",
    "    \n",
    "    #driver = webdriver.Chrome(chromedriver)\n",
    "    #driver.get(listing_urls_list[i])\n",
    "    \n",
    "    #if i//5 == 0:\n",
    "    #    sleep(random.uniform(60,120))\n",
    "        \n",
    "    ####     \n",
    "    #session=requests.Session()\n",
    "    #session.headers = user_agent#{'User-Agent': ua.random} #'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}\n",
    "    #print(user_agent)\n",
    "    ##base_url='https://www.realtor.com'\n",
    "    ##re_list=[]\n",
    "    ##realtor_default_count=44\n",
    "    ##page_counter=1\n",
    "    ##search_url=''.join([base_url, '/realestateandhomes-search/Sacramento_CA'])\n",
    "    #page=session.get(listing_urls_list[i])\n",
    "    #c=page.content\n",
    "    #soup=BeautifulSoup(c,\"html.parser\")\n",
    "    ####\n",
    "    \n",
    "    #options = Options()\n",
    "    #ua = UserAgent()\n",
    "    #userAgent = ua.random\n",
    "    #print(userAgent)\n",
    "    #options.add_argument(f'user-agent={userAgent}')\n",
    "    #driver = webdriver.Chrome(chrome_options=options, executable_path=chromedriver)\n",
    "    #driver.get(listing_urls_list[i])\n",
    "\n",
    "    ###\n",
    "    \n",
    "    '''options = Options()\n",
    "    ua = UserAgent()\n",
    "    userAgent = ua.random\n",
    "    #print(userAgent)\n",
    "    options.add_argument(f'user-agent={userAgent}')\n",
    "    driver = webdriver.Chrome(chrome_options=options, executable_path=chromedriver)\n",
    "    driver.get(listing_urls_list[i])\n",
    "    #user_agent = {'User-agent': 'Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)'}\n",
    "    #response  = requests.get(listing_urls_list[i], headers = user_agent)\n",
    "    \n",
    "    sleep(random.uniform(60,100))'''\n",
    "    ###\n",
    "    \n",
    "   \n",
    "    \n",
    "    PROXY = proxies[count].get_address()\n",
    "    \n",
    "    \n",
    "    print(PROXY)\n",
    "    webdriver.DesiredCapabilities.CHROME['proxy']={\n",
    "                                                    \"httpProxy\":PROXY,\n",
    "                                                    \"ftpProxy\":PROXY,\n",
    "                                                    \"sslProxy\":PROXY,\n",
    "\n",
    "                                                    \"proxyType\":\"MANUAL\",\n",
    "\n",
    "                                                    }\n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "    driver.get(listing_urls_list[i])\n",
    "    \n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "\n",
    "    driver.close()\n",
    "    \n",
    "    #insert listing data into mongo database\n",
    "    col.insert_one(listing_data)\n",
    "    print(listing_data)\n",
    "    count += 1\n",
    "    \n",
    "    #sleep(random.uniform(120,180)) #pause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import requests\n",
    "import random\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "def get_free_proxies():\n",
    "    url = \"https://free-proxy-list.net/\"\n",
    "    # get the HTTP response and construct soup object\n",
    "    soup = bs(requests.get(url).content, \"html.parser\")\n",
    "    proxies = []\n",
    "    for row in soup.find(\"table\", attrs={\"id\": \"proxylisttable\"}).find_all(\"tr\")[1:]:\n",
    "        tds = row.find_all(\"td\")\n",
    "        try:\n",
    "            ip = tds[0].text.strip()\n",
    "            port = tds[1].text.strip()\n",
    "            host = f\"{ip}:{port}\"\n",
    "            proxies.append(host)\n",
    "        except IndexError:\n",
    "            continue\n",
    "    return proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ('hi',50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(num):\n",
    "    return num+12, num-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus, minus = test(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies[1].get_address()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROXY = proxies[0].get_address()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webdriver.DesiredCapabilities.CHROME['proxy']={\n",
    "                                                            \"httpProxy\":PROXY,\n",
    "                                                           \"ftpProxy\":PROXY,\n",
    "                                                           \"sslProxy\":PROXY,\n",
    "                                                           \"proxyType\":\"MANUAL\",\n",
    "                                                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(chromedriver)\n",
    "driver.get(listing_urls_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_urls_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(listing_urls_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_urls_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    check = (soup.find('span', itemprop=\"streetAddress\")).text\n",
    "except:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
